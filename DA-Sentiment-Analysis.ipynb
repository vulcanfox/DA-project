{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bdef17b",
   "metadata": {},
   "source": [
    "# Data analytics coursework "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d4c81566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\adnan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\adnan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Use HuggingFace's datasets library to access the financial_phrasebank dataset\n",
    "from datasets import load_dataset\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import nltk as nltk\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e3db0913",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = [\n",
    "    'data/FiQA_ABSA_task1/task1_headline_ABSA_train.json',\n",
    "    'data/FiQA_ABSA_task1/task1_post_ABSA_train.json'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "29bb0c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances: 1111\n",
      "Number of labels: 1111\n",
      "Number of negative labels: 310\n",
      "Number of neutral labels: 195\n",
      "Number of positive labels: 606\n"
     ]
    }
   ],
   "source": [
    "## Loading data from JSON\n",
    "import json\n",
    "\n",
    "def load_fiqa_sa_from_json(json_files):\n",
    "    train_text = []\n",
    "    train_labels = []\n",
    "\n",
    "    for file in json_files:\n",
    "        with open(file, 'r', encoding='UTF-8') as handle:\n",
    "            dataf = json.load(handle)\n",
    "\n",
    "        dataf_text = [dataf[k][\"sentence\"] for k in dataf.keys()]\n",
    "        # print(len(dataf_text))\n",
    "        train_text.extend(dataf_text)\n",
    "\n",
    "        dataf_labels = [float(dataf[k][\"info\"][0][\"sentiment_score\"]) for k in dataf.keys()]\n",
    "        # print(len(dataf_labels))\n",
    "        train_labels.extend(dataf_labels)\n",
    "\n",
    "    train_text = np.array(train_text)\n",
    "    train_labels = np.array(train_labels)\n",
    "    \n",
    "    return train_text, train_labels\n",
    "\n",
    "\n",
    "def threshold_scores(scores):\n",
    "    \"\"\"\n",
    "    Convert sentiment scores to discrete labels.\n",
    "    0 = negative.\n",
    "    1 = neutral.\n",
    "    2 = positive.\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    for score in scores:\n",
    "        if score < -0.2:\n",
    "            labels.append(0)\n",
    "        elif score > 0.2:\n",
    "            labels.append(2)\n",
    "        else:\n",
    "            labels.append(1)\n",
    "            \n",
    "    return np.array(labels)\n",
    "\n",
    "\n",
    "all_text, all_labels = load_fiqa_sa_from_json(train_files)\n",
    "    \n",
    "print(f'Number of instances: {len(all_text)}')\n",
    "print(f'Number of labels: {len(all_labels)}')\n",
    "\n",
    "all_labels = threshold_scores(all_labels)\n",
    "print(f'Number of negative labels: {np.sum(all_labels==0)}')\n",
    "print(f'Number of neutral labels: {np.sum(all_labels==1)}')\n",
    "print(f'Number of positive labels: {np.sum(all_labels==2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1e5f008f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training instances = 754\n",
      "Number of validation instances = 134\n",
      "Number of test instances = 223\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split test data from training data\n",
    "train_documents, test_documents, train_labels, test_labels = train_test_split(\n",
    "    all_text, \n",
    "    all_labels, \n",
    "    test_size=0.2, \n",
    "    stratify=all_labels  # make sure the same proportion of labels is in the test set and training set\n",
    ")\n",
    "\n",
    "# Split validation data from training data\n",
    "train_documents, val_documents, train_labels, val_labels = train_test_split(\n",
    "    train_documents, \n",
    "    train_labels, \n",
    "    test_size=0.15, \n",
    "    stratify=train_labels  # make sure the same proportion of labels is in the test set and training set\n",
    ")\n",
    "\n",
    "print(f'Number of training instances = {len(train_documents)}')\n",
    "print(f'Number of validation instances = {len(val_documents)}')\n",
    "print(f'Number of test instances = {len(test_documents)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f759bcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What does one instance look like from the training set? \n",
      "\n",
      "$ETN UPGRADE today by MS to overweight.  Excellent company and leadership\n",
      "...and here is its corresponding label \n",
      "\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(f'What does one instance look like from the training set? \\n\\n{train_documents[234]}')\n",
    "print(f'...and here is its corresponding label \\n\\n{train_labels[234]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8bfb43",
   "metadata": {},
   "source": [
    "# Normalization using Lemmatization and bi-grams + unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "443a6c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization and bi+uni-grams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e7aa7a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "        \n",
    "    def __call__(self, tweets):\n",
    "        return [self.wnl.lemmatize(self.wnl.lemmatize(self.wnl.lemmatize(tok, pos='n'), pos='v'), pos='a') for tok in word_tokenize(tweets)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "eff5b79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$', 'aapl', 'reject', 'the', 'hod', '...', 'should', 'head', 'low', '.', 'sit', 'on', 'sideline', 'for', 'now', '$ aapl', 'aapl reject', 'reject the', 'the hod', 'hod ...']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=LemmaTokenizer(), ngram_range=(1,2))\n",
    "vectorizer.fit(train_documents)\n",
    "X_train = vectorizer.transform(train_documents)\n",
    "X_val = vectorizer.transform(val_documents)\n",
    "\n",
    "# Print out some of the features in the vocabulary:\n",
    "print(list(vectorizer.vocabulary_)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "978adde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 11170\n"
     ]
    }
   ],
   "source": [
    "print(f'Vocabulary size: {len(vectorizer.vocabulary_)}')\n",
    "vocabulary = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "41485ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.46      0.57        37\n",
      "           1       0.55      0.25      0.34        24\n",
      "           2       0.68      0.93      0.79        73\n",
      "\n",
      "    accuracy                           0.68       134\n",
      "   macro avg       0.65      0.55      0.57       134\n",
      "weighted avg       0.67      0.68      0.65       134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, train_labels)\n",
    "y_test_pred = classifier.predict(X_val)\n",
    "print(classification_report(val_labels, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955668c0",
   "metadata": {},
   "source": [
    "# Using lexicon features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d3e4c148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\adnan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "838753f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = vectorizer.vocabulary_\n",
    "\n",
    "lex_pos_scores = np.zeros((1, len(vocabulary)))\n",
    "lex_neg_scores = np.zeros((1, len(vocabulary)))\n",
    "\n",
    "for i, term in enumerate(vocabulary):\n",
    "    if term in analyser.lexicon and analyser.lexicon[term] > 0:\n",
    "        lex_pos_scores[0, i] = 1\n",
    "    elif term in analyser.lexicon and analyser.lexicon[term] < 0:\n",
    "        lex_neg_scores[0, i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d0b7078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This enables u to get the total positive and total negative counts for each set:\n",
    "lex_pos_train = np.sum(X_train.multiply(lex_pos_scores), axis=1)\n",
    "lex_pos_test = np.sum(X_val.multiply(lex_pos_scores), axis=1)\n",
    "\n",
    "lex_neg_train = np.sum(X_train.multiply(lex_neg_scores), axis=1)\n",
    "lex_neg_test = np.sum(X_val.multiply(lex_neg_scores), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a7f1ff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "X_train = hstack((X_train, lex_pos_train, lex_neg_train))\n",
    "X_val = hstack((X_val, lex_pos_test, lex_neg_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe016cd4",
   "metadata": {},
   "source": [
    "# Using LogisticRegression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fb1b3bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.38      0.42        37\n",
      "           1       0.75      0.25      0.38        24\n",
      "           2       0.64      0.85      0.73        73\n",
      "\n",
      "    accuracy                           0.61       134\n",
      "   macro avg       0.62      0.49      0.51       134\n",
      "weighted avg       0.62      0.61      0.58       134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, train_labels)\n",
    "y_test_pred = classifier.predict(X_val)\n",
    "\n",
    "print(classification_report(val_labels, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e8a26005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: Apple: Another attempt to break out on Apple but with weak PVT   $AAPL #Trading #investing #aapl https://t.co/DNh7Hgv22V; true label = 1, prediction = 2.\n",
      "Tweet: @Stockoptionexpert: $MAT - 6%, big trader added 10000 April put contracts 3 days ago  http://stks.co/c1Ols; true label = 0, prediction = 2.\n",
      "Tweet: Covered my small $MWW short @ 7.99 for a .16 loss. Flat on the day. All cash now.; true label = 2, prediction = 0.\n",
      "Tweet: StanChart and RBS struggle in Bank of England stress tests; true label = 0, prediction = 2.\n",
      "Tweet: FTSE rallies off three-month low, boosted by StanChart, Sainsbury; true label = 2, prediction = 0.\n",
      "Tweet: Randgold profit hit by poor gold price but dividend still increases; true label = 1, prediction = 0.\n",
      "Tweet: $XLB the weakest sector this year and possible false breakout  http://stks.co/dL1Z; true label = 0, prediction = 2.\n",
      "Tweet: The Boeing Company (NYSE:BA) Bearish Trader bets $550K that Stock Will Sell Off 9.79% by July Expiry $BA http://stks.co/tCSE; true label = 0, prediction = 2.\n",
      "Tweet: $PLUG bear raid; true label = 0, prediction = 2.\n",
      "Tweet: UPDATE 1-Meggitt reiterates annual outlook after tough 2014; true label = 1, prediction = 2.\n"
     ]
    }
   ],
   "source": [
    "# Key part is investigating the errors, so let's do that:\n",
    "error_indexes = y_test_pred != val_labels  # compare predictions to gold labels\n",
    "\n",
    "# get the text of tweets where the classifier made an error:\n",
    "tweets_err = np.array(val_documents)[error_indexes]\n",
    "\n",
    "# WRITE YOUR CODE HERE\n",
    "pred_err = y_test_pred[error_indexes]\n",
    "gold_err = np.array(val_labels)[error_indexes]\n",
    "\n",
    "for i in range(10):  # just print the first ten\n",
    "    print(f'Tweet: {tweets_err[i]}; true label = {gold_err[i]}, prediction = {pred_err[i]}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e421be6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14b8194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d051bc56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analytics",
   "language": "python",
   "name": "data_analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
