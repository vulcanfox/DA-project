{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bdef17b",
   "metadata": {},
   "source": [
    "# Data analytics coursework "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d4c81566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Use HuggingFace's datasets library to access the financial_phrasebank dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e3db0913",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = [\n",
    "    'data/FiQA_ABSA_task1/task1_headline_ABSA_train.json',\n",
    "    'data/FiQA_ABSA_task1/task1_post_ABSA_train.json'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "29bb0c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances: 1111\n",
      "Number of labels: 1111\n",
      "Number of negative labels: 310\n",
      "Number of neutral labels: 195\n",
      "Number of positive labels: 606\n"
     ]
    }
   ],
   "source": [
    "## Loading data from JSON\n",
    "import json\n",
    "\n",
    "def load_fiqa_sa_from_json(json_files):\n",
    "    train_text = []\n",
    "    train_labels = []\n",
    "\n",
    "    for file in json_files:\n",
    "        with open(file, 'r', encoding='UTF-8') as handle:\n",
    "            dataf = json.load(handle)\n",
    "\n",
    "        dataf_text = [dataf[k][\"sentence\"] for k in dataf.keys()]\n",
    "        # print(len(dataf_text))\n",
    "        train_text.extend(dataf_text)\n",
    "\n",
    "        dataf_labels = [float(dataf[k][\"info\"][0][\"sentiment_score\"]) for k in dataf.keys()]\n",
    "        # print(len(dataf_labels))\n",
    "        train_labels.extend(dataf_labels)\n",
    "\n",
    "    train_text = np.array(train_text)\n",
    "    train_labels = np.array(train_labels)\n",
    "    \n",
    "    return train_text, train_labels\n",
    "\n",
    "\n",
    "def threshold_scores(scores):\n",
    "    \"\"\"\n",
    "    Convert sentiment scores to discrete labels.\n",
    "    0 = negative.\n",
    "    1 = neutral.\n",
    "    2 = positive.\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    for score in scores:\n",
    "        if score < -0.2:\n",
    "            labels.append(0)\n",
    "        elif score > 0.2:\n",
    "            labels.append(2)\n",
    "        else:\n",
    "            labels.append(1)\n",
    "            \n",
    "    return np.array(labels)\n",
    "\n",
    "\n",
    "all_text, all_labels = load_fiqa_sa_from_json(train_files)\n",
    "    \n",
    "print(f'Number of instances: {len(all_text)}')\n",
    "print(f'Number of labels: {len(all_labels)}')\n",
    "\n",
    "all_labels = threshold_scores(all_labels)\n",
    "print(f'Number of negative labels: {np.sum(all_labels==0)}')\n",
    "print(f'Number of neutral labels: {np.sum(all_labels==1)}')\n",
    "print(f'Number of positive labels: {np.sum(all_labels==2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1e5f008f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training instances = 754\n",
      "Number of validation instances = 134\n",
      "Number of test instances = 223\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split test data from training data\n",
    "train_documents, test_documents, train_labels, test_labels = train_test_split(\n",
    "    all_text, \n",
    "    all_labels, \n",
    "    test_size=0.2, \n",
    "    stratify=all_labels  # make sure the same proportion of labels is in the test set and training set\n",
    ")\n",
    "\n",
    "# Split validation data from training data\n",
    "train_documents, val_documents, train_labels, val_labels = train_test_split(\n",
    "    train_documents, \n",
    "    train_labels, \n",
    "    test_size=0.15, \n",
    "    stratify=train_labels  # make sure the same proportion of labels is in the test set and training set\n",
    ")\n",
    "\n",
    "print(f'Number of training instances = {len(train_documents)}')\n",
    "print(f'Number of validation instances = {len(val_documents)}')\n",
    "print(f'Number of test instances = {len(test_documents)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f759bcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What does one instance look like from the training set? \n",
      "\n",
      "$ETN UPGRADE today by MS to overweight.  Excellent company and leadership\n",
      "...and here is its corresponding label \n",
      "\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(f'What does one instance look like from the training set? \\n\\n{train_documents[234]}')\n",
    "print(f'...and here is its corresponding label \\n\\n{train_labels[234]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8bfb43",
   "metadata": {},
   "source": [
    "# Normalization using Lemmatization and bi-grams + unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "443a6c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\adnan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\adnan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization and bi+uni-grams\n",
    "import nltk as nltk\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e7aa7a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "        \n",
    "    def __call__(self, tweets):\n",
    "        return [self.wnl.lemmatize(self.wnl.lemmatize(self.wnl.lemmatize(tok, pos='n'), pos='v'), pos='a') for tok in word_tokenize(tweets)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eff5b79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adnan\\anaconda3\\envs\\data_analytics\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['update', '3-bp', 'settle', 'oil', 'spill-related', 'claim', 'with', 'halliburton', ',', 'transocean', 'update 3-bp', '3-bp settle', 'settle oil', 'oil spill-related', 'spill-related claim', 'claim with', 'with halliburton', 'halliburton ,', ', transocean', 'u.k.']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=LemmaTokenizer(), ngram_range=(1,2))\n",
    "vectorizer.fit(train_documents)\n",
    "X_train = vectorizer.transform(train_documents)\n",
    "X_test = vectorizer.transform(test_documents)\n",
    "\n",
    "# Print out some of the features in the vocabulary:\n",
    "print(list(vectorizer.vocabulary_)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "978adde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 11151\n"
     ]
    }
   ],
   "source": [
    "print(f'Vocabulary size: {len(vectorizer.vocabulary_)}')\n",
    "vocabulary = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955668c0",
   "metadata": {},
   "source": [
    "# Using lexicon features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d3e4c148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\adnan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "838753f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = vectorizer.vocabulary_\n",
    "\n",
    "lex_pos_scores = np.zeros((1, len(vocabulary)))\n",
    "lex_neg_scores = np.zeros((1, len(vocabulary)))\n",
    "\n",
    "for i, term in enumerate(vocabulary):\n",
    "    if term in analyser.lexicon and analyser.lexicon[term] > 0:\n",
    "        lex_pos_scores[0, i] = 1\n",
    "    elif term in analyser.lexicon and analyser.lexicon[term] < 0:\n",
    "        lex_neg_scores[0, i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d0b7078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This enables u to get the total positive and total negative counts for each set:\n",
    "lex_pos_train = np.sum(X_train.multiply(lex_pos_scores), axis=1)\n",
    "lex_pos_test = np.sum(X_test.multiply(lex_pos_scores), axis=1)\n",
    "\n",
    "lex_neg_train = np.sum(X_train.multiply(lex_neg_scores), axis=1)\n",
    "lex_neg_test = np.sum(X_test.multiply(lex_neg_scores), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a7f1ff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "X_train = hstack((X_train, lex_pos_train, lex_neg_train))\n",
    "X_test = hstack((X_test, lex_pos_test, lex_neg_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fb1b3bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.45      0.55        62\n",
      "           1       0.67      0.21      0.31        39\n",
      "           2       0.66      0.93      0.78       122\n",
      "\n",
      "    accuracy                           0.67       223\n",
      "   macro avg       0.68      0.53      0.55       223\n",
      "weighted avg       0.68      0.67      0.63       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, train_labels)\n",
    "y_test_pred = classifier.predict(X_test)\n",
    "\n",
    "print(classification_report(test_labels, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e8a26005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: $EA points to the two Facebook games and accuses $ZNGA of copyright infringement. http://stks.co/g3A1; true label = 0, prediction = 2.\n",
      "Tweet: $MFLX up  pre mkt. Looks like GAP has been filled....lookin 4 short opt here; true label = 0, prediction = 2.\n",
      "Tweet: $AAPL afternoon selloff as usual will be brutal. get ready to lose a ton of money.; true label = 0, prediction = 2.\n",
      "Tweet: @mugatushair Now it is time to short $TSLA; true label = 0, prediction = 2.\n",
      "Tweet: $SPY Less than 0.2% down and people are calling it bearish. Some heading for exits already. Maybe 1% down will be \"the crash\"? Disturbing!; true label = 1, prediction = 0.\n",
      "Tweet: @chessNwine: $IWM 30-Minute Chart. Small caps threatening descending triangle breakdown under $110.20.  http://stks.co/r0KKm; true label = 0, prediction = 2.\n",
      "Tweet: Insight hires Aviva's David Hillier for multi-asset team; true label = 1, prediction = 2.\n",
      "Tweet: Bilfinger Industrial Services win Â£100m BP contract extension; true label = 1, prediction = 2.\n",
      "Tweet: Buffett's Berkshire builds Deere stake, dumps Exxon; true label = 2, prediction = 0.\n",
      "Tweet: Academics claim Google Android two-factor authentication is breakable. #security #authentication #hacking $goog https://t.co/nJx4mnrGLo; true label = 0, prediction = 2.\n"
     ]
    }
   ],
   "source": [
    "# Key part is investigating the errors, so let's do that:\n",
    "error_indexes = y_test_pred != test_labels  # compare predictions to gold labels\n",
    "\n",
    "# get the text of tweets where the classifier made an error:\n",
    "tweets_err = np.array(test_documents)[error_indexes]\n",
    "\n",
    "# WRITE YOUR CODE HERE\n",
    "pred_err = y_test_pred[error_indexes]\n",
    "gold_err = np.array(test_labels)[error_indexes]\n",
    "\n",
    "for i in range(10):  # just print the first ten\n",
    "    print(f'Tweet: {tweets_err[i]}; true label = {gold_err[i]}, prediction = {pred_err[i]}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e421be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation = KFold(n_splits=10, shuffle=True)\n",
    "# Setting max_depth\n",
    "max_d = 30\n",
    "# Creating train and validation error arrays.\n",
    "train_error = [[] for _ in range(max_d)]\n",
    "val_error = [[] for _ in range(max_d)]\n",
    "for d in tqdm(range(max_d)): # Using tqdm to show progress bar :)\n",
    "    #Instantiate our RF regressor\n",
    "    regressor = RandomForestRegressor(n_estimators= 10, max_depth=d+1)\n",
    "    # Split data into training and validation\n",
    "    for train_index, val_index in cross_validation.split(Xtr):\n",
    "        Xtrain, Xval, Ytrain, Yval = Xtr.iloc[train_index], Xtr.iloc[val_index], Ytr.iloc[train_index], Ytr.iloc[val_index]\n",
    "        # fitting the model on our data\n",
    "        RFG_model=regressor.fit(Xtrain, Ytrain.values.flatten())\n",
    "        # now we make predictions for training and validation splits\n",
    "        y_pred_train=RFG_model.predict(Xtrain)\n",
    "        y_pred_val=RFG_model.predict(Xval)\n",
    "        # we get the root mean squared error\n",
    "        train_error[d].append(mean_squared_error(Ytrain,y_pred_train, squared=False))\n",
    "        val_error[d].append(mean_squared_error(Yval,y_pred_val, squared=False))\n",
    "# Fetching the mean for training and validation errors across splits for all depths\n",
    "avg_train_error = np.mean(train_error, axis=1)\n",
    "avg_val_error = np.mean(val_error, axis=1)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analytics",
   "language": "python",
   "name": "data_analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
