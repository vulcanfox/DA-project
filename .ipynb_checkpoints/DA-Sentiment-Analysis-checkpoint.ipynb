{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bdef17b",
   "metadata": {},
   "source": [
    "# Data analytics coursework "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4c81566",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\adnan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\adnan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\adnan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Use HuggingFace's datasets library to access the financial_phrasebank dataset\n",
    "from datasets import load_dataset\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "import nltk as nltk\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3db0913",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = [\n",
    "    'data/FiQA_ABSA_task1/task1_headline_ABSA_train.json',\n",
    "    'data/FiQA_ABSA_task1/task1_post_ABSA_train.json'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29bb0c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances: 1111\n",
      "Number of labels: 1111\n",
      "Number of negative labels: 310\n",
      "Number of neutral labels: 195\n",
      "Number of positive labels: 606\n"
     ]
    }
   ],
   "source": [
    "## Loading data from JSON\n",
    "import json\n",
    "\n",
    "def load_fiqa_sa_from_json(json_files):\n",
    "    train_text = []\n",
    "    train_labels = []\n",
    "\n",
    "    for file in json_files:\n",
    "        with open(file, 'r', encoding='UTF-8') as handle:\n",
    "            dataf = json.load(handle)\n",
    "\n",
    "        dataf_text = [dataf[k][\"sentence\"] for k in dataf.keys()]\n",
    "        # print(len(dataf_text))\n",
    "        train_text.extend(dataf_text)\n",
    "\n",
    "        dataf_labels = [float(dataf[k][\"info\"][0][\"sentiment_score\"]) for k in dataf.keys()]\n",
    "        # print(len(dataf_labels))\n",
    "        train_labels.extend(dataf_labels)\n",
    "\n",
    "    train_text = np.array(train_text)\n",
    "    train_labels = np.array(train_labels)\n",
    "    \n",
    "    return train_text, train_labels\n",
    "\n",
    "\n",
    "def threshold_scores(scores):\n",
    "    \"\"\"\n",
    "    Convert sentiment scores to discrete labels.\n",
    "    0 = negative.\n",
    "    1 = neutral.\n",
    "    2 = positive.\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    for score in scores:\n",
    "        if score < -0.2:\n",
    "            labels.append(0)\n",
    "        elif score > 0.2:\n",
    "            labels.append(2)\n",
    "        else:\n",
    "            labels.append(1)\n",
    "            \n",
    "    return np.array(labels)\n",
    "\n",
    "\n",
    "all_text, all_labels = load_fiqa_sa_from_json(train_files)\n",
    "    \n",
    "print(f'Number of instances: {len(all_text)}')\n",
    "print(f'Number of labels: {len(all_labels)}')\n",
    "\n",
    "all_labels = threshold_scores(all_labels)\n",
    "print(f'Number of negative labels: {np.sum(all_labels==0)}')\n",
    "print(f'Number of neutral labels: {np.sum(all_labels==1)}')\n",
    "print(f'Number of positive labels: {np.sum(all_labels==2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1e5f008f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training instances = 710\n",
      "Number of validation instances = 178\n",
      "Number of test instances = 223\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split test data from training data\n",
    "train_documents, test_documents, train_labels, test_labels = train_test_split(\n",
    "    all_text, \n",
    "    all_labels, \n",
    "    test_size=0.2, \n",
    "    stratify=all_labels  # make sure the same proportion of labels is in the test set and training set\n",
    ")\n",
    "\n",
    "# Split validation data from training data\n",
    "train_documents, val_documents, train_labels, val_labels = train_test_split(\n",
    "    train_documents, \n",
    "    train_labels, \n",
    "    test_size=0.2, \n",
    "    stratify=train_labels  # make sure the same proportion of labels is in the test set and training set\n",
    ")\n",
    "\n",
    "print(f'Number of training instances = {len(train_documents)}')\n",
    "print(f'Number of validation instances = {len(val_documents)}')\n",
    "print(f'Number of test instances = {len(test_documents)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f759bcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What does one instance look like from the training set? \n",
      "\n",
      "Credit Suisse poaches Prudential's Thiam for Asian push\n",
      "...and here is its corresponding label \n",
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(f'What does one instance look like from the training set? \\n\\n{train_documents[234]}')\n",
    "print(f'...and here is its corresponding label \\n\\n{train_labels[234]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8bfb43",
   "metadata": {},
   "source": [
    "# Preprocessing using Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422fe568",
   "metadata": {},
   "source": [
    "We create a lemmatizer token that reduces words to their root forms. This reduces the vocabulary size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e7aa7a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "        \n",
    "    def __call__(self, tweets):\n",
    "        return [self.wnl.lemmatize(self.wnl.lemmatize(self.wnl.lemmatize(tok, pos='n'), pos='v'), pos='a') for tok in word_tokenize(tweets)]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7932f42",
   "metadata": {},
   "source": [
    "# Using bi-grams + unigrams as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "eff5b79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adnan\\anaconda3\\envs\\data_analytics\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ocwen', 'reach', 'settlement', 'with', 'california', 'regulator', 'ocwen reach', 'reach settlement', 'settlement with', 'with california', 'california regulator', 'rt', '@', 'cash_cow', '$', 'tlt', 'still', 'ha', 'a', 'rise']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=LemmaTokenizer(), ngram_range=(1,2))\n",
    "vectorizer.fit(train_documents)\n",
    "X_train = vectorizer.transform(train_documents)\n",
    "X_val = vectorizer.transform(val_documents)\n",
    "X_test_documents = vectorizer.transform(test_documents)\n",
    "# Print out some of the features in the vocabulary:\n",
    "print(list(vectorizer.vocabulary_)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "978adde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 10638\n"
     ]
    }
   ],
   "source": [
    "print(f'Vocabulary size: {len(vectorizer.vocabulary_)}')\n",
    "vocabulary = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded1bed2",
   "metadata": {},
   "source": [
    "## Fitting to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bf44eb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.54      0.63        50\n",
      "           1       0.90      0.29      0.44        31\n",
      "           2       0.69      0.94      0.79        97\n",
      "\n",
      "    accuracy                           0.71       178\n",
      "   macro avg       0.78      0.59      0.62       178\n",
      "weighted avg       0.74      0.71      0.69       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, train_labels)\n",
    "y_test_pred = classifier.predict(X_val)\n",
    "print(classification_report(val_labels, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955668c0",
   "metadata": {},
   "source": [
    "# Using POS-NEG lexicon features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d3e4c148",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "838753f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = vectorizer.vocabulary_\n",
    "\n",
    "lex_pos_scores = np.zeros((1, len(vocabulary)))\n",
    "lex_neg_scores = np.zeros((1, len(vocabulary)))\n",
    "\n",
    "for i, term in enumerate(vocabulary):\n",
    "    if term in analyser.lexicon and analyser.lexicon[term] > 0:\n",
    "        lex_pos_scores[0, i] = 1\n",
    "    elif term in analyser.lexicon and analyser.lexicon[term] < 0:\n",
    "        lex_neg_scores[0, i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d0b7078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This enables u to get the total positive and total negative counts for each set:\n",
    "lex_pos_train = np.sum(X_train.multiply(lex_pos_scores), axis=1)\n",
    "lex_pos_val = np.sum(X_val.multiply(lex_pos_scores), axis=1)\n",
    "lex_pos_test = np.sum(X_test_documents.multiply(lex_pos_scores), axis=1)\n",
    "\n",
    "lex_neg_train = np.sum(X_train.multiply(lex_neg_scores), axis=1)\n",
    "lex_neg_val = np.sum(X_val.multiply(lex_neg_scores), axis=1)\n",
    "lex_neg_test = np.sum(X_test_documents.multiply(lex_neg_scores), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a7f1ff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = hstack((X_train, lex_pos_train, lex_neg_train))\n",
    "X_val = hstack((X_val, lex_pos_val, lex_neg_val))\n",
    "X_test_documents = hstack((X_test_documents, lex_pos_test, lex_neg_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79970dc2",
   "metadata": {},
   "source": [
    "## refitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fb1b3bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.54      0.63        50\n",
      "           1       0.90      0.29      0.44        31\n",
      "           2       0.69      0.94      0.79        97\n",
      "\n",
      "    accuracy                           0.71       178\n",
      "   macro avg       0.78      0.59      0.62       178\n",
      "weighted avg       0.74      0.71      0.69       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, train_labels)\n",
    "y_test_pred = classifier.predict(X_val)\n",
    "# Checking performance\n",
    "print(classification_report(val_labels, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e8a26005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: CompaniesLSE adds ex-SEC head Schapiro to board; true label = 1, prediction = 2.\n",
      "Tweet: $AMD big dumping... would not touch it for a while; true label = 0, prediction = 2.\n",
      "Tweet: Looks like its booking a one way ticket to its 40 week MA near 50. Losing 10 week here $LULU http://chart.ly/7xb9h9b; true label = 1, prediction = 2.\n",
      "Tweet: Sheryl Sandberg Sells 109,000 Shares of Facebook Inc $FB Stock https://t.co/3vXT7AMnpk via @RatingsNetwork; true label = 1, prediction = 2.\n",
      "Tweet: $RIG whos ever pushing this is crazy, get ready for suspended dividend (turning into growth stock) blow out earnings, and major buyback, lol; true label = 1, prediction = 2.\n",
      "Tweet: $SPY Tomorrow party time for the Bears!! $GOOG and $MSFT -5.5%; true label = 0, prediction = 2.\n",
      "Tweet: $GPS Gap September Comparable Store Sales -4%; true label = 0, prediction = 2.\n",
      "Tweet: Glencore fight back over debt fears lifts shares; true label = 2, prediction = 0.\n",
      "Tweet: $ENDP being sued by FTC.....nobody will buy them with that hanging over their heads; true label = 0, prediction = 2.\n",
      "Tweet: #Apple breaks major support, here are some levels to watch - http://stks.co/jRmW $AAPL $QQQ; true label = 0, prediction = 2.\n"
     ]
    }
   ],
   "source": [
    "# Key part is investigating the errors, so let's do that:\n",
    "error_indexes = y_test_pred != val_labels  # compare predictions to gold labels\n",
    "\n",
    "# get the text of tweets where the classifier made an error:\n",
    "tweets_err = np.array(val_documents)[error_indexes]\n",
    "\n",
    "# WRITE YOUR CODE HERE\n",
    "pred_err = y_test_pred[error_indexes]\n",
    "gold_err = np.array(val_labels)[error_indexes]\n",
    "\n",
    "for i in range(10):  # just print the first ten\n",
    "    print(f'Tweet: {tweets_err[i]}; true label = {gold_err[i]}, prediction = {pred_err[i]}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679324ba",
   "metadata": {},
   "source": [
    "### Performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "36b7100d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.55      0.61        62\n",
      "           1       0.71      0.13      0.22        39\n",
      "           2       0.69      0.94      0.80       122\n",
      "\n",
      "    accuracy                           0.69       223\n",
      "   macro avg       0.70      0.54      0.54       223\n",
      "weighted avg       0.69      0.69      0.64       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's test the performance on the test set.\n",
    "y_test_pred = classifier.predict(X_test_documents)\n",
    "# Checking performance\n",
    "print(classification_report(test_labels, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeff3b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analytics",
   "language": "python",
   "name": "data_analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
