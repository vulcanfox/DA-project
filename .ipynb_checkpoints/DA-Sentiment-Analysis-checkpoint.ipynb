{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bdef17b",
   "metadata": {},
   "source": [
    "# Data analytics coursework "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d4c81566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\adnan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\adnan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\adnan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Use HuggingFace's datasets library to access the financial_phrasebank dataset\n",
    "from datasets import load_dataset\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "import nltk as nltk\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e3db0913",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = [\n",
    "    'data/FiQA_ABSA_task1/task1_headline_ABSA_train.json',\n",
    "    'data/FiQA_ABSA_task1/task1_post_ABSA_train.json'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "29bb0c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances: 1111\n",
      "Number of labels: 1111\n",
      "Number of negative labels: 310\n",
      "Number of neutral labels: 195\n",
      "Number of positive labels: 606\n"
     ]
    }
   ],
   "source": [
    "## Loading data from JSON\n",
    "import json\n",
    "\n",
    "def load_fiqa_sa_from_json(json_files):\n",
    "    train_text = []\n",
    "    train_labels = []\n",
    "\n",
    "    for file in json_files:\n",
    "        with open(file, 'r', encoding='UTF-8') as handle:\n",
    "            dataf = json.load(handle)\n",
    "\n",
    "        dataf_text = [dataf[k][\"sentence\"] for k in dataf.keys()]\n",
    "        # print(len(dataf_text))\n",
    "        train_text.extend(dataf_text)\n",
    "\n",
    "        dataf_labels = [float(dataf[k][\"info\"][0][\"sentiment_score\"]) for k in dataf.keys()]\n",
    "        # print(len(dataf_labels))\n",
    "        train_labels.extend(dataf_labels)\n",
    "\n",
    "    train_text = np.array(train_text)\n",
    "    train_labels = np.array(train_labels)\n",
    "    \n",
    "    return train_text, train_labels\n",
    "\n",
    "\n",
    "def threshold_scores(scores):\n",
    "    \"\"\"\n",
    "    Convert sentiment scores to discrete labels.\n",
    "    0 = negative.\n",
    "    1 = neutral.\n",
    "    2 = positive.\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    for score in scores:\n",
    "        if score < -0.2:\n",
    "            labels.append(0)\n",
    "        elif score > 0.2:\n",
    "            labels.append(2)\n",
    "        else:\n",
    "            labels.append(1)\n",
    "            \n",
    "    return np.array(labels)\n",
    "\n",
    "\n",
    "all_text, all_labels = load_fiqa_sa_from_json(train_files)\n",
    "    \n",
    "print(f'Number of instances: {len(all_text)}')\n",
    "print(f'Number of labels: {len(all_labels)}')\n",
    "\n",
    "all_labels = threshold_scores(all_labels)\n",
    "print(f'Number of negative labels: {np.sum(all_labels==0)}')\n",
    "print(f'Number of neutral labels: {np.sum(all_labels==1)}')\n",
    "print(f'Number of positive labels: {np.sum(all_labels==2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "1e5f008f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training instances = 754\n",
      "Number of validation instances = 134\n",
      "Number of test instances = 223\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split test data from training data\n",
    "train_documents, test_documents, train_labels, test_labels = train_test_split(\n",
    "    all_text, \n",
    "    all_labels, \n",
    "    test_size=0.2, \n",
    "    stratify=all_labels  # make sure the same proportion of labels is in the test set and training set\n",
    ")\n",
    "\n",
    "# Split validation data from training data\n",
    "train_documents, val_documents, train_labels, val_labels = train_test_split(\n",
    "    train_documents, \n",
    "    train_labels, \n",
    "    test_size=0.15, \n",
    "    stratify=train_labels  # make sure the same proportion of labels is in the test set and training set\n",
    ")\n",
    "\n",
    "print(f'Number of training instances = {len(train_documents)}')\n",
    "print(f'Number of validation instances = {len(val_documents)}')\n",
    "print(f'Number of test instances = {len(test_documents)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f759bcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What does one instance look like from the training set? \n",
      "\n",
      "$KNDI Break that HOD on volume, and we have a nice consolidation completed for another run.\n",
      "...and here is its corresponding label \n",
      "\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(f'What does one instance look like from the training set? \\n\\n{train_documents[234]}')\n",
    "print(f'...and here is its corresponding label \\n\\n{train_labels[234]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8bfb43",
   "metadata": {},
   "source": [
    "# Preprocessing using Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422fe568",
   "metadata": {},
   "source": [
    "We create a lemmatizer token that reduces words to their root forms. This reduces the vocabulary size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e7aa7a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "        \n",
    "    def __call__(self, tweets):\n",
    "        return [self.wnl.lemmatize(self.wnl.lemmatize(self.wnl.lemmatize(tok, pos='n'), pos='v'), pos='a') for tok in word_tokenize(tweets)]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7932f42",
   "metadata": {},
   "source": [
    "# Using bi-grams + unigrams as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "eff5b79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adnan\\anaconda3\\envs\\data_analytics\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['persimmon', 'share', 'price', 'climb', 'on', '23', '%', 'rise', 'in', 'full-year', 'revenue', 'persimmon share', 'share price', 'price climb', 'climb on', 'on 23', '23 %', '% rise', 'rise in', 'in full-year']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=LemmaTokenizer(), ngram_range=(1,2))\n",
    "vectorizer.fit(train_documents)\n",
    "X_train = vectorizer.transform(train_documents)\n",
    "X_val = vectorizer.transform(val_documents)\n",
    "\n",
    "# Print out some of the features in the vocabulary:\n",
    "print(list(vectorizer.vocabulary_)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "978adde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 11136\n"
     ]
    }
   ],
   "source": [
    "print(f'Vocabulary size: {len(vectorizer.vocabulary_)}')\n",
    "vocabulary = vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded1bed2",
   "metadata": {},
   "source": [
    "## Fitting to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "bf44eb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.46      0.52        37\n",
      "           1       0.60      0.12      0.21        24\n",
      "           2       0.68      0.93      0.79        73\n",
      "\n",
      "    accuracy                           0.66       134\n",
      "   macro avg       0.62      0.51      0.50       134\n",
      "weighted avg       0.64      0.66      0.61       134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, train_labels)\n",
    "y_test_pred = classifier.predict(X_val)\n",
    "print(classification_report(val_labels, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955668c0",
   "metadata": {},
   "source": [
    "# Using POS-NEG lexicon features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d3e4c148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\adnan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "838753f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = vectorizer.vocabulary_\n",
    "\n",
    "lex_pos_scores = np.zeros((1, len(vocabulary)))\n",
    "lex_neg_scores = np.zeros((1, len(vocabulary)))\n",
    "\n",
    "for i, term in enumerate(vocabulary):\n",
    "    if term in analyser.lexicon and analyser.lexicon[term] > 0:\n",
    "        lex_pos_scores[0, i] = 1\n",
    "    elif term in analyser.lexicon and analyser.lexicon[term] < 0:\n",
    "        lex_neg_scores[0, i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d0b7078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This enables u to get the total positive and total negative counts for each set:\n",
    "lex_pos_train = np.sum(X_train.multiply(lex_pos_scores), axis=1)\n",
    "lex_pos_test = np.sum(X_val.multiply(lex_pos_scores), axis=1)\n",
    "\n",
    "lex_neg_train = np.sum(X_train.multiply(lex_neg_scores), axis=1)\n",
    "lex_neg_test = np.sum(X_val.multiply(lex_neg_scores), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a7f1ff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train = hstack((X_train, lex_pos_train, lex_neg_train))\n",
    "X_val = hstack((X_val, lex_pos_test, lex_neg_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79970dc2",
   "metadata": {},
   "source": [
    "## refitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "fb1b3bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.49      0.54        37\n",
      "           1       0.60      0.12      0.21        24\n",
      "           2       0.69      0.93      0.79        73\n",
      "\n",
      "    accuracy                           0.66       134\n",
      "   macro avg       0.63      0.51      0.51       134\n",
      "weighted avg       0.65      0.66      0.62       134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, train_labels)\n",
    "y_test_pred = classifier.predict(X_val)\n",
    "# Checking performance\n",
    "print(classification_report(val_labels, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e8a26005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: CompaniesHoward Davies appointment as RBS director delayed; true label = 1, prediction = 0.\n",
      "Tweet: LSE-Deutsche BÃ¶rse dealmakers wrong to ignore Brexit risk; true label = 0, prediction = 2.\n",
      "Tweet: Chime Communications Set To Be Acquired By WPP And Providence; true label = 2, prediction = 0.\n",
      "Tweet: $FB  rejecting HIGHS shortable...at 109; true label = 0, prediction = 2.\n",
      "Tweet: Stakes High for AstraZeneca Heart Drug Facing Tough Competition; true label = 0, prediction = 2.\n",
      "Tweet: $YHOO fishy action. New party interested (DailyMail) bounce & retreats. Not short by any means, but action questions big up move. Thoughts?; true label = 1, prediction = 2.\n",
      "Tweet: CompaniesDixons Carphone to close 134 UK stores as sales jump; true label = 1, prediction = 2.\n",
      "Tweet: Philip Morris, BAT Sue Over Law Taking Branding Off Packs; true label = 1, prediction = 0.\n",
      "Tweet: $tsla X recall not a big deal... the problem is now they will have an excuse to guide way way lower...; true label = 1, prediction = 0.\n",
      "Tweet: AB InBev to Sell SABMiller Stake in China's Snow Beer; true label = 1, prediction = 2.\n"
     ]
    }
   ],
   "source": [
    "# Key part is investigating the errors, so let's do that:\n",
    "error_indexes = y_test_pred != val_labels  # compare predictions to gold labels\n",
    "\n",
    "# get the text of tweets where the classifier made an error:\n",
    "tweets_err = np.array(val_documents)[error_indexes]\n",
    "\n",
    "# WRITE YOUR CODE HERE\n",
    "pred_err = y_test_pred[error_indexes]\n",
    "gold_err = np.array(val_labels)[error_indexes]\n",
    "\n",
    "for i in range(10):  # just print the first ten\n",
    "    print(f'Tweet: {tweets_err[i]}; true label = {gold_err[i]}, prediction = {pred_err[i]}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e421be6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b7100d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeff3b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analytics",
   "language": "python",
   "name": "data_analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
